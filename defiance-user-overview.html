
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Overview &#8212; DEFIANCE Module 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">Â¶</a></h1>
<p>The <em>ns-3</em> DEFIANCE module is a reinforcement learning (RL) framework for <em>ns-3</em>. It allows the simulation of distributed RL in networks. It can handle single-agent and multi-agent RL scenarios.</p>
<p>The user performs the following steps to carry out the RL experiment:</p>
<ol class="arabic simple">
<li><p>Implement the network topology and traffic using standard <em>ns-3</em> code.</p></li>
<li><p>To define how observations and reward signals are collected, how actions are executed in the environment and how the agents perform inference and training, subclass from the provided <a class="reference internal" href="defiance-user.html#defiance-rl-applications"><span class="std std-ref">RL-Applications</span></a>. Abstract classes for the different subtasks are provided via the <a class="reference internal" href="defiance-user.html#defiance-agent-application"><span class="std std-ref">AgentApplication</span></a>, <a class="reference internal" href="defiance-user.html#defiance-observation-application"><span class="std std-ref">ObservationApplication</span></a>, <a class="reference internal" href="defiance-user.html#defiance-reward-application"><span class="std std-ref">RewardApplication</span></a> and <a class="reference internal" href="defiance-user.html#defiance-action-application"><span class="std std-ref">ActionApplication</span></a>. These applications are installed in the simulation via the <a class="reference internal" href="defiance-user.html#defiance-application-helper"><span class="std std-ref">RlApplicationHelper</span></a>.</p></li>
<li><p>Specify how data is exchanged between these components and specify the communication structure via channels. The lowest level of abstraction our framework proposes is using <a class="reference internal" href="defiance-user-channel-interface.html#defiance-channel-interface"><span class="std std-ref">ChannelInterfaces</span></a> for this. The framework also provides a <a class="reference internal" href="defiance-user.html#defiance-communication-helper"><span class="std std-ref">CommunicationHelper</span></a> class to simplify the communication setup.</p></li>
<li><p>Finally, use the utilities provided by <a class="reference internal" href="defiance-references.html#ns3-ai"><span class="std std-ref">ns3-ai</span></a> to interact with the simulation as an RL environment.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An in-depth documentation of the multi-agent interface we added to <em>ns3-ai</em> can be found <a class="reference external" href="https://github.com/DEFIANCE-project/ns3-ai/blob/main/docs/multi-agent.md">here</a>. This interface is also used by the DEFIANCE framework. In case you are interested in how the framework functions or think about extending DEFIANCE, we recommend to take a look at these docs or the <cite>blog post &lt;https://medium.com/&#64;oliver.zimmermann/reinforcement-learning-in-ns3-part-1-698b9c30c0cd&gt;</cite> we wrote about it.</p>
</div>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="defiance.html">DEFIANCE Module</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="defiance-design.html">1. Design Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="defiance-user.html">2. User Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="defiance-references.html">3. References</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="defiance.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2024.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.3.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/defiance-user-overview.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>